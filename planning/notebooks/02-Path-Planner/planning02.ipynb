{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">\n",
    "<img src=\"../../assets/images/dtlogo.png\" alt=\"Duckietown\" width=\"50%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Write a path planner\n",
    "\n",
    "In this series of exercises<br>you will write path planners of increasing complexity. \n",
    "\n",
    "You need to have solved the `collision-checker` exercise, because you will need a collision checker. \n",
    "\n",
    "**Note: This is a code-only exercise: you don't need the Duckiebot**.\n",
    "\n",
    "You will be working in the [`planner.py`][file] file.\n",
    "\n",
    "[file]: ../../packages/planning/planner.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Path planning problems\n",
    "\n",
    "We will consider several variations of path planning problems.\n",
    "\n",
    "There are **two complexity axes**: dynamic constraints and environment complexity.\n",
    "\n",
    "\n",
    "For **dynamic constraints** we have 2 cases:\n",
    "\n",
    "1. The basic case is that of a differential drive robot, which can turn in place. \n",
    "2. The advanced case is a car-like dynamics: the robot cannot turn in place, because there is a bound on the maximum path curvature.\n",
    "\n",
    "For **environment complexity** we have 3 cases:\n",
    "\n",
    "1. The basic case is that of an **empty** environment.\n",
    "2. The intermediate case is that of an environment with **static** obstacles.\n",
    "3. The advanced case is that of an environment with **dynamic** obstacles (with known motion).\n",
    "\n",
    "You should be able to do the challenges *without the curvature constraints*.\n",
    "\n",
    "For the most efficient solution of the challenges with the curvature constraints, you would need to know more about sampling-based motion planning.\n",
    "\n",
    "The combinations give rise to 6 challenges, summarized in the following table:\n",
    "\n",
    "\n",
    "| challenge                                                      | dynamic constraints     | environment        |\n",
    "|----------------------------------------------------------------|-------------------------|--------------------|\n",
    "| [lx22-planning-dd-empty-vali][lx22-planning-dd-empty-vali]     | differential drive      | empty              |\n",
    "| [lx22-planning-cc-empty-vali][lx22-planning-cc-empty-vali]     | + curvature constraints | empty              |\n",
    "| [lx22-planning-dd-static-vali][lx22-planning-dd-static-vali]   | differential drive      | static obstacles   |\n",
    "| [lx22-planning-cc-static-vali][lx22-planning-cc-static-vali]   | + curvature constraints | static obstacles   |\n",
    "| [lx22-planning-dd-dynamic-vali][lx22-planning-dd-dynamic-vali] | differential drive      | dynamic obstacles  |\n",
    "| [lx22-planning-cc-dynamic-vali][lx22-planning-cc-dynamic-vali] | + curvature constraints | dynamic obstacles  |\n",
    "\n",
    "[lx22-planning-dd-empty-vali]: https://challenges.duckietown.org/v4/humans/challenges/lx22-planning-dd-empty-vali\n",
    "[lx22-planning-cc-empty-vali]: https://challenges.duckietown.org/v4/humans/challenges/lx22-planning-cc-empty-vali\n",
    "[lx22-planning-dd-static-vali]: https://challenges.duckietown.org/v4/humans/challenges/lx22-planning-dd-static-vali\n",
    "[lx22-planning-cc-static-vali]: https://challenges.duckietown.org/v4/humans/challenges/lx22-planning-cc-static-vali\n",
    "[lx22-planning-dd-dynamic-vali]: https://challenges.duckietown.org/v4/humans/challenges/lx22-planning-dd-dynamic-vali\n",
    "[lx22-planning-cc-dynamic-vali]: https://challenges.duckietown.org/v4/humans/challenges/lx22-planning-cc-dynamic-vali\n",
    "\n",
    "(Except for the first two, there are also corresponding `-test` challenges with hidden traces that are used for grading.)\n",
    "\n",
    "### No obstacles\n",
    "<!--\n",
    "<p style=\"text-align: center\">\n",
    "<video width=\"96%\" controls autoplay>\n",
    "<source src=\"../../assets/images/dd-empty.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "</p>\n",
    "-->\n",
    "<img src=\"../../assets/images/dd-empty.png\" alt=\"empty\" style=\"width:800px;\" />\n",
    "\n",
    "</br>\n",
    "\n",
    "### Static obstacles\n",
    "<!--\n",
    "<p style=\"float:left; text-align: left\">\n",
    "<video width=\"96%\" controls autoplay>\n",
    "<source src=\"../../assets/images/dd-static.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "</p>\n",
    "-->\n",
    "<img src=\"../../assets/images/dd-static.png\" style=\"width:800px;\" />\n",
    "\n",
    "</br>\n",
    "\n",
    "### Dynamic obstacles\n",
    "<!--\n",
    "<p style=\"text-align: center\">\n",
    "<video width=\"96%\" controls autoplay>\n",
    "<source src=\"../../assets/images/dd-dynamic.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "</p>\n",
    "-->\n",
    "<img src=\"../../assets/images/dd-dynamic.png\" style=\"width:800px;\" />\n",
    "\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures and protocol\n",
    "\n",
    "The data structures are defined in the [`dt-protocols`](https://github.com/duckietown/dt-protocols) package. \n",
    "\n",
    "In particular, you can look in [`collision_protocol.py`][file] the data structures to use.<br>\n",
    "We **strongly** suggest opening the [`collision_protocol.py`][file] link/file in a separate window, and cross-referencing the information given here with the code definition given in the file.\n",
    "\n",
    "[file]: https://github.com/duckietown/dt-protocols/blob/daffy/src/dt_protocols/collision_protocol.py\n",
    "\n",
    "Note: <br>\n",
    "The data structures used for the planner are an extension of the data structures used in the `collision-checker` exercise. <br>\n",
    "Please refer to that documentation for a description of `PlacedPrimitive`, `FriendlyPose`, `Primitive`, `Rectangle`, `Circle`, etc.\n",
    "\n",
    "This is the protocol:\n",
    "\n",
    "1. The planner receives first a message of type `PlanningSetup`, which contains a description of the environment, the robot body, and the dynamic constraints.\n",
    "2. Then the planner receives a sequence of `PlanningQuery`s. The query contains a start and a target pose for the robot. \n",
    "3. The planner must respond with a `PlanningResult` message containing the  plan.\n",
    "\n",
    "More in detail:\n",
    "\n",
    "The `PlanningSetup` object is an extension of the `MapDefinition` type used in the `collision-checker` exercise. <br>\n",
    "- `MapDefinition` contains a description of the environment and robot body. <br>\n",
    "- `PlanningSetup` extends it with the planning constraints.\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PlanningSetup(MapDefinition):\n",
    "    bounds: Rectangle\n",
    "    max_linear_velocity_m_s: float\n",
    "    min_linear_velocity_m_s: float\n",
    "    max_angular_velocity_deg_s: float\n",
    "    max_curvature: float\n",
    "    tolerance_xy_m: float\n",
    "    tolerance_theta_deg: float\n",
    "```\n",
    "\n",
    "Environment:\n",
    "\n",
    "* `bounds` is a `Rectangle` that gives the overall area where the robot is allowed.\n",
    "\n",
    "Dynamic constraints:\n",
    "\n",
    "* `min_linear_velocity_m_s` and `max_linear_velocity_m_s` give the interval of linear velocity allowed in the x direction (in m/s).\n",
    "* `max_angular_velocity_deg_s` is the maximum turning rate (in deg/s)\n",
    "* `max_curvature` is the maximum curvature allowed. <br>\n",
    "Example: if `max_curvature` is 4, it means that the radius of the smallest circle that the robot can trace is 1/4 = 0.25 m.\n",
    "\n",
    "Tolerances:\n",
    "\n",
    "* `tolerance_xy_m` is the maximum tolerance for errors in the final pose for x-y.\n",
    "* `tolerance_theta_deg` is the maximum tolerance for errors in the final pose for the orientation.\n",
    "\n",
    "The `PlanningQuery` message contains the start and target pose:\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PlanningQuery:\n",
    "    start: FriendlyPose\n",
    "    target: FriendlyPose\n",
    "```\n",
    "\n",
    "The `PlanningResult` message is:\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PlanningResult:\n",
    "    feasible: bool\n",
    "    plan: Optional[List[PlanStep]]\n",
    "```\n",
    "\n",
    "In your response, you should first declare if you found a feasible solution with the first boolean.<br>\n",
    "(Note that in the scoring we penalize if you declared that you found a feasible solution when you don't have it more that if you just declare it infeasible).\n",
    "\n",
    "In the case of a feasible answer, you should return the plan, which is a list of `PlanStep`s.\n",
    "\n",
    "A `PlanStep` contains the duration of the step as well as angular and linear velocity held constant during the step:\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PlanStep:\n",
    "    duration: float\n",
    "    velocity_x_m_s: float\n",
    "    angular_velocity_deg_s: float\n",
    "```\n",
    "\n",
    "This is an example (contained in the planner template) that constructs a plan that traces a square of a given length in minimum time:\n",
    "\n",
    "\n",
    "```python\n",
    "# Let's trace a square of side L at maximum velocity.\n",
    "L = 1.0\n",
    "duration_straight_m_s = L / self.params.max_linear_velocity_m_s\n",
    "duration_turn_deg_s = 90.0 / self.params.max_angular_velocity_deg_s\n",
    "\n",
    "# The plan will be: straight, turn, straight, turn, straight, turn, straight, turn\n",
    "\n",
    "straight = PlanStep(duration=duration_straight_m_s, angular_velocity_deg_s=0.0,\n",
    "                    velocity_x_m_s=self.params.max_linear_velocity_m_s)\n",
    "turn = PlanStep(duration=duration_turn_deg_s,\n",
    "                angular_velocity_deg_s=self.params.max_angular_velocity_deg_s,\n",
    "                velocity_x_m_s=0.0)\n",
    "\n",
    "plan = [straight, turn] * 4\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extension: moving obstacles\n",
    "\n",
    "A `PlacedPrimitive` can also have an optional `Motion` object associated, which, if not equal to `None`, specifies its path in time (you do not need to consider the `appearance` attribute).\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class PlacedPrimitive:\n",
    "    pose: FriendlyPose\n",
    "    primitive: Primitive\n",
    "    motion: Optional[Motion] = None\n",
    "    appearance: Optional[Appearance] = None\n",
    "```\n",
    "\n",
    "\n",
    "The motion is described as a sequence of `PlanStep`s:\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Motion:\n",
    "    steps: List[PlanStep]\n",
    "```\n",
    "\n",
    "(Note here that we are doing motion planning in dynamic environments with *known* motion).\n",
    "\n",
    "\n",
    "In the `dt_protocols` module you will find a useful function called `simulate` which you can use to predict the trajectories for the obstacles (and for yourself as well):\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class SimulationResult:\n",
    "    poses: List[FriendlyPose]\n",
    "    ts: List[float]\n",
    "\n",
    "def simulate(start: FriendlyPose, steps: List[PlanStep]) -> SimulationResult:\n",
    "    \"\"\" Applies the plan to an initial pose to obtain a sequence of time/poses. \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "The challenges output will be a video like the following. <br>\n",
    "It will be in a folder like: \n",
    "\n",
    "`/tmp/![username]/duckietown/dt-challenges-runner/local-evals/lx22-planning-dd-static-vali/![date]/step1-![X]of4/tmp/1[random]/results/env![XX]`\n",
    "\n",
    "<!--\n",
    "<p style=\"text-align: center\">\n",
    "<video width=\"96%\" controls autoplay>\n",
    "<source src=\"../../assets/images/dynamic.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "</p>\n",
    "-->\n",
    "<img src=\"../../assets/images/dynamic.png\" alt=\"dyn\" style=\"width:800px;\" />\n",
    "\n",
    "On the left, you will see the start and target pose, and the animation of the result of your plan.\n",
    "\n",
    "On the right, you will see plots for:\n",
    "\n",
    "* linear velocity\n",
    "* angular velocity\n",
    "* distance from obstacles\n",
    "* path curvature (+inf when you turn in place)\n",
    "\n",
    "\n",
    "The red bars identify points in which a constraint was violated. In this case, the robot violates the constraint of not colliding with obstacles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge scoring criteria\n",
    "\n",
    "There are 5 scoring criteria, from most to least important:\n",
    "\n",
    "1. `mistakes`: The fraction of queries for which you declared a feasible plan, but the plan was not feasible. Very bad!<br>\n",
    "   If you don't have a feasible plan, don't pretend that you have one. Lower is better.<br>\n",
    "2. `success_ratio`: The fraction of queries for which you provided a feasible plan. Higher is better.<br>\n",
    "3. `duration`: the average length of the trajectory. Lower is better.<br>\n",
    "4. `complexity`: the average number of steps in your plan. The fewer steps, the better.<br>\n",
    "5. `avg_min_distance`: The average distance from the obstacles. Higher is better: we prefer plans with more clearance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for implementing the planners\n",
    "\n",
    "\n",
    "### Start with the empty obstacles challenge\n",
    "\n",
    "Start with the challenges with the empty environment. You should be able to compute a plan that moves from pose A to pose B.\n",
    "\n",
    "One easy way to do it is the following:\n",
    "\n",
    "1. Starting at pose A, turn towards pose B.\n",
    "2. Go forward until you reach B in x,y coordinates.\n",
    "3. Adjust the orientation to B's orientation.\n",
    "\n",
    "This simple algorithm will work, but it produces path with infinite curvature, as you turn in place.\n",
    "\n",
    "You might want to implement a function of this signature:\n",
    "\n",
    "```python\n",
    "def connect_poses(ps: PlanningSetup, a: FriendlyPose, b: FriendlyPose) -> List[PlanStep]:\n",
    "    ...\n",
    "```\n",
    "\n",
    "(Also note that, without loss of generality, you can assume that `a` is the identity, by translating `b` in the frame of `a`.)\n",
    "\n",
    "### Continue with the static obstacles case\n",
    "\n",
    "To solve the static obstacles case, you can apply a graph-search algorithm.\n",
    "\n",
    "You should create a cube of states: the generic node has coordinates (x,y,theta). <br>\n",
    "The coordinates  x, y are distributed in a grid in the `bounds` given by the `PlanningSetup` message. <br>\n",
    "The thetas are distributed in [0, 360], but note that 0 and 360 are the same point! <br>\n",
    "You likely want to have `thetas = [0, 10, 20, ..., 340, 350]`, and make sure that 0 and 350 are neighbors.\n",
    "\n",
    "The resolution that you need depends on the `tolerance` parameters.\n",
    "\n",
    "For creating the graph it is convenient to use the `networkx` library (as in the previous notebook).\n",
    "\n",
    "You should connect two nodes with an edge if `connect_poses` can find a plan to connect them. <br>\n",
    "And you might want to store this plan so that you don't need to recompute it later. <br>\n",
    "Also, store the total duration as the weight for the edge.\n",
    "\n",
    "`networkx` already has a [Dijkstra](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm) implementation. You will realize that the actual graph search is super fast compared to the other operations, so it's not worth to implement [A*](https://en.wikipedia.org/wiki/A*_search_algorithm) (though it is a nice exercise).\n",
    "\n",
    "\n",
    "### Try the dynamic case\n",
    "\n",
    "The dynamic case is conceptually the same.\n",
    "\n",
    "You should use spatio-temporal nodes. Each node has coordinates `(x,y,theta,t)`.\n",
    "\n",
    "You can only connect two nodes `(...,t1)` and `(...,t2)` if `t2 > t1`.\n",
    "\n",
    "The connection function to write now should have the form\n",
    "\n",
    "```python\n",
    "def connect_temporal_poses(ps: PlanningSetup, a: FriendlyPose, b: FriendlyPose, dt: float) -> List[PlanStep]:\n",
    "    ...\n",
    "```\n",
    "\n",
    "because you don't want the fastest plan, but rather the plan that takes exactly `dt = t2 - t1`.\n",
    "\n",
    "### Finally, the bounded curvature case\n",
    "\n",
    "You can try to adapt your grid search approach to this case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💻 Test your path planner in the simulator\n",
    "\n",
    "At the moment, there is no VNC simulator for this exercise. Running `dts code workbench --sim` will produce the error \n",
    "```bash \n",
    "dts :  Recipe must contain a 'assets/environment' directory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚙 Test the path planner on your Duckiebot\n",
    "\n",
    "At the moment, the exercise cannot be tested on the real Duckiebot. Running `dts code workbench -b ROBOT_NAME` will produce an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local evaluation and remote submission of your homework exercise\n",
    "\n",
    "\n",
    "## Local evaluation\n",
    "\n",
    "1. Open a terminal, navigate to the exercise folder and run:\n",
    "\n",
    "        dts code evaluate --challenge CHALLENGE_NAME\n",
    "\n",
    "where CHALLENGE_NAME is one among: <br>\n",
    "- `lx22-planning-dd-empty-vali`<br>\n",
    "- `lx22-planning-cc-empty-vali`<br>\n",
    "- `lx22-planning-dd-static-vali`<br>\n",
    "- `lx22-planning-cc-static-vali`<br>\n",
    "- `lx22-planning-dd-dynamic-vali`<br>\n",
    "- `lx22-planning-cc-dynamic-vali`\n",
    "        \n",
    "\n",
    "2. The evaluation output is saved locally at the end of the evaluation process. \n",
    "\n",
    "## Remote submission\n",
    "\n",
    "You can submit your agent for evaluation by: \n",
    "\n",
    "1. Opening a terminal on your computer, navigating to the exercise folder and running:\n",
    "\n",
    "        dts code submit\n",
    "        \n",
    "\n",
    "2. The result of the submission can be visualize on the AIDO challenges website:\n",
    "\n",
    "After some processing, you should see something like this:\n",
    "\n",
    "```\n",
    "\n",
    "~        ## Challenge lx22-planning-cc-dynamic-vali - LX - Planning dynamic (validation)\n",
    "~        \n",
    "~                Track this submission at:\n",
    "~        \n",
    "~                    https://challenges.duckietown.org/v4/humans/submissions/SUBMISSION-NUMBER\n",
    "~        \n",
    "~                You can follow its fate using:\n",
    "~        \n",
    "~                    $ dts challenges follow --submission SUBMISSION-NUMBER\n",
    "~        \n",
    "~                You can speed up the evaluation using your own evaluator:\n",
    "~        \n",
    "~                    $ dts challenges evaluator --submission SUBMISSION-NUMBER\n",
    "~        \n",
    "~                For more information, see the manual at https://docs.duckietown.org/daffy/AIDO/out/\n",
    "~        \n",
    "~        \n",
    "~        ## Challenge lx22-planning-cc-static-vali - LX - Planning constrained (validation)\n",
    "~        \n",
    "~                Track this submission at:\n",
    "~        \n",
    "~                    https://challenges.duckietown.org/v4/humans/submissions/SUBMISSION-NUMBER\n",
    "~        \n",
    "~                You can follow its fate using:\n",
    "~        \n",
    "~                    $ dts challenges follow --submission SUBMISSION-NUMBER\n",
    "~        \n",
    "~                You can speed up the evaluation using your own evaluator:\n",
    "~        \n",
    "~                    $ dts challenges evaluator --submission SUBMISSION-NUMBER\n",
    "~        \n",
    "~                For more information, see the manual at https://docs.duckietown.org/daffy/AIDO/out/\n",
    "\n",
    "```\n",
    "etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.98700000000002 360.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "t1 = -41.987+360\n",
    "t2 = 0\n",
    "delta1 = abs(t2-t1)\n",
    "delta2 = abs(360+t2-t1)\n",
    "delta = min(delta1,delta2)\n",
    "shift = 0.0\n",
    "if delta == delta2 : shift += 360\n",
    "dir = (((abs(t1)-abs(t2+shift)) < 0) * 1 - 0.5 ) *2\n",
    "print(delta, shift, dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
